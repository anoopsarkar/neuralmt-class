<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>SFU NLP class: Homework 5 | Reranking</title>

    <!-- CSS -->
    <link href="dist/css/bootstrap.min.css" rel="stylesheet">
    <link href="dist/css/bootstrap-glyphicons.css" rel="stylesheet">
    <link href="assets/css/nlp-class.css" rel="stylesheet">   
    <link href="//netdna.bootstrapcdn.com/font-awesome/4.0.3/css/font-awesome.css" rel="stylesheet">

    <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
      <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
    <![endif]-->

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script>

    <!-- MathJax -->
    <script type="text/javascript"
      src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
    </script>
  </head>
  <body>
    <a class="sr-only" href="#content">Skip to main content</a>

    <!-- Docs master nav -->
    <header class="navbar navbar-fixed-top navbar-default" role="banner">
      <div class="container">
        <div class="row">
        <div class="navbar-header">
          <button class="navbar-toggle" type="button" data-toggle="collapse" data-target=".navbar-collapse">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>
          <ul class="nav navbar-nav">
            <li id="main_page"><a href="index.html" class="navbar-brand">Natural Language Processing</a></li>
          </ul>
        </div>
        <nav class="collapse navbar-collapse" role="navigation">
          <ul class="nav navbar-nav">
            <li id="syllabus"><a href="syllabus.html">Syllabus</a></li>
            <li id="homework">
              <a class="dropdown-toggle" data-toggle="dropdown" href="#">Homework <span class="caret"></span></a>
              <ol class="dropdown-menu">
                <li><a href="hw0.html">0. Setup</a></li>
                <li><a href="hw1.html">1. Word Segmentation</a></li>
                <li><a href="hw2.html">2. Phrasal Chunking</a></li>
                <li><a href="hw3.html">3. Word Alignment</a></li>
                <li><a href="hw4.html">4. Translation Decoding</a></li>
                <li><a href="hw5.html">5. Translation Reranking</a></li>
              </ol>
            </li>
            <li id="leaderboard"><a href="leaderboard.html">Leaderboard</a></li>
            <li id="project"><a href="project.html">Project</a></li>
            <li id="faq"><a href="faq.html">FAQ</a></li>
          </ul>
        </nav>
      </div>
      </div>
    </header>

    <div class="container">
      <div class="row">
        <div class="col-sm-2 hidden-sm hidden-xs">
          <a href="http://www.statmt.org/moses/?n=FactoredTraining.Tuning"> 
          <img src="assets/img/mixer.jpg" class="img-responsive img-rounded" alt=""/>
          </a> 
          <span class="text-muted"><i>Adjust the weights of the log-linear model to get the best translation score.</i></span>
        </div>
        <div class="col-sm-10">
          <h1 id="translation-reranking-span-classtext-mutedhomework-5span">Translation Reranking <span class="text-muted">Homework 5</span></h1>

<p class="text-muted">Due on Tuesday, November 22, 2016</p>

<p>In <a href="hw2.html">Homework 2</a> you learned to train a discriminative learner,
In <a href="hw4.html">Homework 4</a> you built a decoder that can produce n-best 
outputs in the target language given a source language sentence.</p>

<p>In this assignment we will give you some sentences from French news
articles, and you will use the metric to improve a model that chooses
from a set of possible English translations generated by a
state-of-the-art machine translation decoder. <strong>Your challenge is
to use discriminative learning to choose the best translations.</strong></p>

<h2 id="getting-started">Getting Started</h2>

<p>You must have git and python (2.7) on your system to run the
assignments.</p>

<p>If you have already cloned the <code class="highlighter-rouge">nlp-class-hw</code> repository,
then do the following to get the files for Homework 3:</p>

<div class="highlighter-rouge"><pre class="highlight"><code># go to the directory where you did a git clone before
cd nlp-class-hw
git pull origin master
</code></pre>
</div>

<p>Or you can create a new directory that does a fresh clone of the
repository:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>git clone https://github.com/anoopsarkar/nlp-class-hw.git
</code></pre>
</div>

<p>In the <code class="highlighter-rouge">reranker</code> directory you will find several python programs
and data sets that you will use for this assignment.</p>

<p>The reranker reads candidate translations from the file <code class="highlighter-rouge">data/test.nbest</code>.
Every candidate translation <script type="math/tex">e\in E(f)</script> of an input sentence <script type="math/tex">f</script>
has an associated feature vector <script type="math/tex">h(e,f)</script>. <script type="math/tex">E(f)</script> is the n-best
list of candidate translations for <script type="math/tex">f</script>. The reranker takes a
parameter vector <script type="math/tex">\theta</script> whose length is equal to that of
<script type="math/tex">h(e,f)</script>. By default, <script type="math/tex">\theta</script> assigns uniform weight to each
features, so each weight is equal to <script type="math/tex">\frac{1}{len(h(e,f))}</script>.
For each <script type="math/tex">f</script>, the reranker returns <script type="math/tex">\hat{e}</script> according to the
following decision function.</p>

<center>
$$\hat{e} = \arg\max_{e\in E(f)} \theta \cdot h(e,f)$$
</center>

<h3 id="reranking-with-default-weights">Reranking with default weights</h3>

<p>Use the default reranker simply produces uniform weights for
all features in the file <code class="highlighter-rouge">data/train.nbest</code>:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>python default.py &gt; default.weights
</code></pre>
</div>

<p>The default simply ignores the training data. See below on how to
use the training data to learn weights.</p>

<p>You can use the default weights with the reranker program
provided to you:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>python rerank.py -w default.weights &gt; default.output
</code></pre>
</div>

<p>The reranker code tries to predict the best translation for each
sentence in the file <code class="highlighter-rouge">data/test.nbest</code>. The output file contains
the best translations according to the weights provided to the
reranker.</p>

<h3 id="score-the-output">Score the output</h3>

<p>Score the output using <code class="highlighter-rouge">score-reranker.py</code>:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>python score-reranker.py &lt; default.output
</code></pre>
</div>

<p>This prints out the BLEU score for the output file by comparing it
with <code class="highlighter-rouge">data/test.en</code>. The score is for the first 250 sentences of
the 500 sentences in the test set.</p>

<p>Do not use <code class="highlighter-rouge">test.nbest</code> or <code class="highlighter-rouge">test.en</code> in your implementation of
reranking or you will get a zero mark on this assignment. Using the
reference data in <code class="highlighter-rouge">test.en</code> we can obtain an oracle score (the best
possible BLEU score we can get by reranking). See below for how to
compute the oracle score.</p>

<p>You can do it all at once:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>python rerank.py -w default.weights | python score-reranker.py
</code></pre>
</div>

<h3 id="the-features">The features</h3>

<p>The files <code class="highlighter-rouge">train.nbest</code> and <code class="highlighter-rouge">test.nbest</code> have six feature functions:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>LMScore ReorderingScore p(f|e) lex(f|e) p(e|f) lex(e|f) 
</code></pre>
</div>

<p>The feature functions are explained below:</p>

<ol>
  <li><code class="highlighter-rouge">LMScore</code>: the language model score for this candidate</li>
  <li><code class="highlighter-rouge">ReorderingScore</code>: the sum of the distortion penalties for this translation</li>
  <li><code class="highlighter-rouge">p(f|e)</code>: the inverse phrase translation probability</li>
  <li><code class="highlighter-rouge">lex(f|e)</code>: the inverse lexical weighting</li>
  <li><code class="highlighter-rouge">p(e|f)</code>: the direct phrase translation probability</li>
  <li><code class="highlighter-rouge">lex(e|f)</code>: the direct lexical weighting</li>
</ol>

<p>For example, here are the 5-best outputs for the first sentence in the training data. Each has a feature vector with values for the above feature functions:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>0 ||| barack obama will become the fourth american president to receive the nobel peace prize ||| -25.014 -1.000 -5.000 -2.000 -14.000 -6.080
0 ||| barack obama will be the fourth american president to receive the nobel peace prize ||| -26.457 -1.000 -4.000 -2.000 -14.000 -6.080
0 ||| barack obama will be the fourth us president to receive the nobel peace prize ||| -26.781 -1.000 -5.000 -2.000 -14.000 -6.080
0 ||| barack obama would be the fourth american president to receive the nobel peace prize ||| -26.311 -1.000 -5.000 -2.000 -14.000 -6.080
0 ||| barack obama will become the fourth american president to receive the nobel peace prize winner ||| -25.899 -1.000 -5.000 -2.000 -15.000 -6.514
</code></pre>
</div>

<p>Your task is to find weights for these features to pick a better
translation out of the n-best list for each input sentence. This
task is called reranking.</p>

<h3 id="the-oracle-score">The oracle score</h3>

<p>How much better can you get by reranking. The program <code class="highlighter-rouge">oracle.py</code>
uses the reference sentences to show you the upper bound in
the improvement.</p>

<div class="highlighter-rouge"><pre class="highlight"><code>python oracle.py | python score-reranker.py
</code></pre>
</div>

<p>The oracle uses the references in <code class="highlighter-rouge">test.en</code> but your reranker cannot
use that information to learn the weights. Learn your weights
<strong>only</strong> on the training data.</p>

<h3 id="your-reranker">Your reranker</h3>

<p>The program <code class="highlighter-rouge">default.py</code> simply ignores the training data:</p>

<ul>
  <li><code class="highlighter-rouge">train.nbest</code>: n-best lists for training</li>
  <li><code class="highlighter-rouge">train.en</code>: target language references for learning how to rank the n-best list</li>
  <li><code class="highlighter-rouge">train.fr</code>: source language sentences used as input to a decoder to create the n-best list</li>
</ul>

<p>Your job is to use the training data to learn weights for all the
features in <code class="highlighter-rouge">train.nbest</code>. Then you can use your weights to produce
a better output using <code class="highlighter-rouge">rerank.py</code>:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>python rerank.py -w your-weights &gt; your-output
</code></pre>
</div>

<p>You can then score your output in the same way as shown above:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>python score-reranker.py &lt; your-output
</code></pre>
</div>

<h3 id="leaderboard">Leaderboard</h3>

<p>You should upload the output of <code class="highlighter-rouge">rerank.py</code> using weights that you
learn by using <code class="highlighter-rouge">train.nbest</code> (n-best list for training), <code class="highlighter-rouge">train.en</code>
(the reference target language output for training) and <code class="highlighter-rouge">train.fr</code>
(the source language input for training) to the leaderboard on
<a href="https://sfu-nlp-class.appspot.com">sfu-nlp-class.appspot.com</a>.</p>

<p>The score will be almost identical to the local score reported by
<code class="highlighter-rouge">score-reranker.py</code> so please do not upload excessively to the
leaderboard. The leaderboard scores on all 500 sentences in
<code class="highlighter-rouge">data/test.nbest</code> while the local score is on the first 250 sentences.</p>

<h3 id="options">Options</h3>

<div class="highlighter-rouge"><pre class="highlight"><code>python default.py -h
</code></pre>
</div>

<p>This shows the different options you can use in your training
algorithm implementation.</p>

<h3 id="data">Data</h3>

<p>The data directory contains several files derived from a French-English
newswire translation task.</p>

<ul>
  <li><code class="highlighter-rouge">train.fr</code>: Training data consisting of French news text</li>
  <li><code class="highlighter-rouge">train.en</code>: Human translations of the French training data</li>
  <li><code class="highlighter-rouge">train.nbest</code>: N-best machine translations of the French training data</li>
  <li><code class="highlighter-rouge">test.fr</code>: 500 sentences of French test data</li>
  <li><code class="highlighter-rouge">test.en</code>: Human translations of the first 250 sentences of the French test</li>
  <li><code class="highlighter-rouge">test.nbest</code>: N-best machine translations of the French test data</li>
</ul>

<h2 id="the-challenge">The Challenge</h2>

<p>The oracle should convince you that it is possible to do <em>much</em>
better than the default reranker. Maybe you can improve it by
changing the parameter vector <script type="math/tex">\theta</script>. Do this using command-line
arguments to <code class="highlighter-rouge">rerank</code>. Try a few different settings. How close can
you get to the oracle BLEU score?</p>

<p>You can improve the parameter vector by trial and error, but that
will not be very efficient. To really improve the system you need
automation. There are two components you can add: informative
features that correlate with BLEU, and effective learning algorithms
that optimize <script type="math/tex">\theta</script> for BLEU. Your task is to improve translation
quality on the blind test set as much as possible by improving these
components.</p>

<h3 id="the-baseline">The Baseline</h3>

<p>For the baseline learning algorithm we will use an algorithm called
PRO (pairwise ranking optimization) which is described in the
following paper:</p>

<blockquote>
  <p><a href="http://www.aclweb.org/anthology/D11-1125">Tuning as Ranking</a>. Mark Hopkins and Jonathan May. EMNLP 2011.</p>
</blockquote>

<p>One caveat is that we will not be generating new candidates using
a decoder in each iteration. This means we will iterate over the
n-best lists provided to you rather than re-decoding to produce
n-best lists for each iteration. This approach is called <em>batch
tuning</em> and explained further in:</p>

<blockquote>
  <p><a href="http://aclweb.org/anthology-new/N/N12/N12-1047v2.pdf">Batch Tuning Strategies for Statistical Machine Translation</a>. Colin Cherry and George Foster. In NAACL 2012.</p>
</blockquote>

<p>Here is a pseudo code version of the PRO algorithm to learn weights for reranking:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>Parameters:
    tau: samples generated from n-best list per input sentence (set to 5000)
    alpha: sampler acceptance cutoff (set to 0.1)
    xi: training data generated from the samples tau (set to 100)
    eta: perceptron learning rate (set to 0.1)
    epochs: number of epochs for perceptron training (set to 5)

for each sentence i:
    collect all the n-best outputs for i
    for each candidate c in the n-best list:
        compute the bleu score b (using bleu.py) for c
        append (c,b) to nbests[i]

for i = 1 to epochs:
    for nbest in nbests:
        get_sample():
            initialize sample to empty list 
            loop tau times:
                randomly choose two items from nbest list, s1 and s2:
                if fabs(s1.smoothed_bleu - s2.smoothed_bleu) &gt; alpha:
                    if s1.smoothed_bleu &gt; s2.smoothed_bleu:
                        sample += (s1, s2)
                    else:
                        sample += (s2, s1)
                else:
                    continue
            return sample
        sort the tau samples from get_sample() using s1.smoothed_bleu - s2.smoothed_bleu
        keep the top xi (s1, s2) values from the sorted list of samples
        do a perceptron update of the parameters theta:
            if theta * s1.features &lt;= theta * s2.features:
                mistakes += 1
                theta += eta * (s1.features - s2.features) # this is vector addition!
return theta
</code></pre>
</div>

<p>Implementing a batch tuning version of PRO will be enough to match
the baseline score.  However, there will still be substantial room
for improvement.  Here are some ideas:</p>

<ul>
  <li>Improve the learning algorithm in PRO (from the perceptron to averaged perceptron, for instance).</li>
  <li>You can add features to <code class="highlighter-rouge">train.nbest</code> and <code class="highlighter-rouge">test.nbest</code>
    <ul>
      <li>Add a feature that counts the number of words.</li>
      <li>Add a feature to count words that appear to be untranslated.</li>
      <li>Add <a href="http://aclweb.org/anthology/N/N04/N04-1021.pdf">an IBM Model 1 score</a> (sum over all alignments) as a feature.</li>
    </ul>
  </li>
  <li>Use <a href="http://aclweb.org/anthology/N/N04/N04-1023.pdf">ordinal regression or uneven margins</a>.</li>
  <li>Find a consensus translation using <a href="http://aclweb.org/anthology//N/N04/N04-1022.pdf">minimum Bayes risk</a>.</li>
  <li>Many, many ideas to improve reranking: using <a href="http://www3.nd.edu/~dchiang/papers/chiang-jmlr12-corrected.pdf">hope and fear</a>.</li>
</ul>

<p>But the sky’s the limit! You can try anything you want, as long
as you follow the ground rules.</p>

<h2 id="ground-rules">Ground Rules</h2>

<ul>
  <li>Each group should submit using one person as the designated uploader.</li>
  <li>You must turn in three things:
    <ol>
      <li>The output from <code class="highlighter-rouge">rerank.py</code> using the weights learned by your program. The output must be uploaded to the <a href="http://sfu-nlp-class.appspot.com">leaderboard submission site</a> using the instructions given above. You can upload new output as often as you like, up until the assignment deadline. The Submit button for showing the test set scores will be unavailable until after the homework deadline and grace days have passed.</li>
      <li>Your code. Each group should assign one member to upload the source code to <a href="https://courses.cs.sfu.ca">Coursys</a> as the submission for Homework 5. The code should be self-contained, self-documenting, and easy to use.</li>
      <li>A clear, mathematical description of your algorithm and its motivation written in scientific style. This needn’t be long, but it should be clear enough that one of your fellow students could re-implement it exactly. Include the file for this writeup as part of the tarball or zip file you will upload to <a href="https://courses.cs.sfu.ca">Coursys</a>. Include also how your group divided up the work load and each group member’s contribution to the homework solution.</li>
    </ol>
  </li>
  <li>You cannot use data or code resources outside of what is provided to you. You can use NLTK but not any NLTK reranking code directly. You cannot use any public implementation of reranking such as the one included in <code class="highlighter-rouge">moses</code>, <code class="highlighter-rouge">Joshua</code>  or <code class="highlighter-rouge">cdec</code> or any other open source decoder.</li>
  <li>For the written description of your algorithm, you can use plain ASCII but for math equations it is better to use either <a href="http://www.latex-project.org/">latex</a> or <a href="https://github.com/gettalong/kramdown">kramdown</a>.  Do <strong>not</strong> use any proprietary or binary file formats such as Microsoft Word.</li>
</ul>

<p>If you have any questions or you’re confused about anything, just ask.</p>

<h4 id="acknowledgements">Acknowledgements</h4>

<p>This assignment is adapted from the decoding homework developed by
<a href="http://cs.jhu.edu/~alopez/">Adam Lopez</a> and subsequently improved
by <a href="http://www.cs.cmu.edu/~cdyer">Chris Dyer</a>.</p>


        </div>
      </div>

      <footer class="text-center text-muted">
        <hr/>
        Last updated September 06, 2016.<br/>
        Forked from the JHU MT class code on <a href="https://github.com/mt-class/jhu">github <i class="fa fa-github-alt"></i></a> by <a href="https://github.com/mjpost">Matt Post</a> and <a href="https://github.com/alopez">Adam Lopez</a>.<br/>
        <br/><br/>
      </footer>
    </div>

    <!-- Page content of course! -->
    <!-- JS and analytics only. -->
    <!-- Bootstrap core JavaScript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="./dist/js/bootstrap.js"></script>
    <script type="text/javascript">
      $(document).ready(function(){
        $("#homework").addClass("active");
      });
    </script>
  </body>
</html>
