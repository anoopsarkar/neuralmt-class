<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>SFU NLP class: Homework 3 | Alignment</title>

    <!-- CSS -->
    <link href="dist/css/bootstrap.min.css" rel="stylesheet">
    <link href="dist/css/bootstrap-glyphicons.css" rel="stylesheet">
    <link href="assets/css/nlp-class.css" rel="stylesheet">   
    <link href="//netdna.bootstrapcdn.com/font-awesome/4.0.3/css/font-awesome.css" rel="stylesheet">

    <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
      <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
    <![endif]-->

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script>

    <!-- MathJax -->
    <script type="text/javascript"
      src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
    </script>
  </head>
  <body>
    <a class="sr-only" href="#content">Skip to main content</a>

    <!-- Docs master nav -->
    <header class="navbar navbar-fixed-top navbar-default" role="banner">
      <div class="container">
        <div class="row">
        <div class="navbar-header">
          <button class="navbar-toggle" type="button" data-toggle="collapse" data-target=".navbar-collapse">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>
          <ul class="nav navbar-nav">
            <li id="main_page"><a href="index.html" class="navbar-brand">Natural Language Processing</a></li>
          </ul>
        </div>
        <nav class="collapse navbar-collapse" role="navigation">
          <ul class="nav navbar-nav">
            <li id="syllabus"><a href="syllabus.html">Syllabus</a></li>
            <li id="homework">
              <a class="dropdown-toggle" data-toggle="dropdown" href="#">Homework <span class="caret"></span></a>
              <ol class="dropdown-menu">
                <li><a href="hw0.html">0. Setup</a></li>
                <li><a href="hw1.html">1. Word Segmentation</a></li>
                <li><a href="hw2.html">2. Phrasal Chunking</a></li>
                <li><a href="hw3.html">3. Word Alignment</a></li>
                <li><a href="hw4.html">4. Translation Decoding</a></li>
                <li><a href="hw5.html">5. Translation Reranking</a></li>
              </ol>
            </li>
            <li id="leaderboard"><a href="leaderboard.html">Leaderboard</a></li>
            <li id="project"><a href="project.html">Project</a></li>
            <li id="faq"><a href="faq.html">FAQ</a></li>
          </ul>
        </nav>
      </div>
      </div>
    </header>

    <div class="container">
      <div class="row">
        <div class="col-sm-2 hidden-sm hidden-xs">
          <a href="http://en.wikipedia.org/wiki/Rosetta_Stone"> 
          <img src="assets/img/rosetta.jpg" class="img-responsive img-rounded" alt=""/>
          </a> 
          <span class="text-muted"><i>Jean-François Champollion used word alignment (starting with the word Ptolemy) to decipher Egyptian hierogyphics.</i></span>
        </div>
        <div class="col-sm-10">
          <h1 id="word-alignment-span-classtext-mutedhomework-3span">Word Alignment <span class="text-muted">Homework 3</span></h1>

<p class="text-muted">Due on Tuesday, October 25, 2016</p>

<p>Word alignment is a key task in building a machine translation system.
We start with a large corpus of aligned sentences called a parallel
corpus. For example, we might have the following sentence pair
from the Canadian Hansards (the published proceedings of the
Canadian parliament):</p>

<div class="highlighter-rouge"><pre class="highlight"><code>monsieur le Orateur , ma question se adresse à le ministre chargé de les transports .
Mr. Speaker , my question is directed to the Minister of Transport .
</code></pre>
</div>

<p>Your task is to find the alignments between the words between
the two languages. For example, given the sentence pair
above, your program should output a word alignment in the
following format that uses the word indices from the two
languages:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>0-0 2-1 3-2 4-3 5-4 7-6 8-7 9-8 10-9 12-10 14-11 15-12
</code></pre>
</div>

<p>This corresponds to an alignment of the words shown in the following table:</p>

<table class="table">
  <tbody>
    <tr>
      <td>0 <code class="highlighter-rouge">monsieur</code></td>
      <td>0 <code class="highlighter-rouge">Mr.</code></td>
    </tr>
    <tr>
      <td>1 <code class="highlighter-rouge">le</code></td>
      <td> </td>
    </tr>
    <tr>
      <td>2 <code class="highlighter-rouge">Orateur</code></td>
      <td>1 <code class="highlighter-rouge">Speaker</code></td>
    </tr>
    <tr>
      <td>3 <code class="highlighter-rouge">,</code></td>
      <td>2 <code class="highlighter-rouge">,</code></td>
    </tr>
    <tr>
      <td>4 <code class="highlighter-rouge">ma</code></td>
      <td>3 <code class="highlighter-rouge">my</code></td>
    </tr>
    <tr>
      <td>5 <code class="highlighter-rouge">question</code></td>
      <td>4 <code class="highlighter-rouge">question</code></td>
    </tr>
    <tr>
      <td>6 <code class="highlighter-rouge">se</code></td>
      <td> </td>
    </tr>
    <tr>
      <td> </td>
      <td>5 <code class="highlighter-rouge">is</code></td>
    </tr>
    <tr>
      <td>7 <code class="highlighter-rouge">adresse</code></td>
      <td>6 <code class="highlighter-rouge">directed</code></td>
    </tr>
    <tr>
      <td>8 <code class="highlighter-rouge">à</code></td>
      <td>7 <code class="highlighter-rouge">to</code></td>
    </tr>
    <tr>
      <td>9 <code class="highlighter-rouge">le</code></td>
      <td>8 <code class="highlighter-rouge">the</code></td>
    </tr>
    <tr>
      <td>10 <code class="highlighter-rouge">ministre</code></td>
      <td>9 <code class="highlighter-rouge">Minister</code></td>
    </tr>
    <tr>
      <td>11 <code class="highlighter-rouge">chargé</code></td>
      <td> </td>
    </tr>
    <tr>
      <td>12 <code class="highlighter-rouge">de</code></td>
      <td>10 <code class="highlighter-rouge">of</code></td>
    </tr>
    <tr>
      <td>14 <code class="highlighter-rouge">transports</code></td>
      <td>11 <code class="highlighter-rouge">Transport</code></td>
    </tr>
    <tr>
      <td>15 <code class="highlighter-rouge">.</code></td>
      <td>12 <code class="highlighter-rouge">.</code></td>
    </tr>
  </tbody>
</table>

<h2 id="getting-started">Getting Started</h2>

<p>You must have git and python (2.7) on your system to run the
assignments.</p>

<p>If you have already cloned the <code class="highlighter-rouge">nlp-class-hw</code> repository,
then do the following to get the files for Homework 3:</p>

<div class="highlighter-rouge"><pre class="highlight"><code># go to the directory where you did a git clone before
cd nlp-class-hw
git pull origin master
</code></pre>
</div>

<p>Or you can create a new directory that does a fresh clone of the
repository:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>git clone https://github.com/anoopsarkar/nlp-class-hw.git
</code></pre>
</div>

<p>In the <code class="highlighter-rouge">aligner</code> directory you will find several python programs
and data sets that you will use for this assignment.  <em>Warning</em>:
the size of the <code class="highlighter-rouge">aligner</code> directory is 51MB.</p>

<p><code class="highlighter-rouge">default.py</code> contains a default training algorithm for the alignment
task.</p>

<div class="highlighter-rouge"><pre class="highlight"><code>python default.py -m default.model
</code></pre>
</div>

<p><code class="highlighter-rouge">default.py</code> implements a complete but very simple alignment
algorithm. For every word, it computes the set of sentences that
the word appears in. Intuititvely, word pairs that appear in similar
sets of sentences are likely to be translations. Our aligner first
computes the similarity of these sets with <a href="http://goo.gl/XS9rps">Dice’s
coefficient</a>.  Given the co-occurence count
<script type="math/tex">C(e,f)</script> of words <script type="math/tex">e</script> and <script type="math/tex">f</script> in the parallel corpus, Dice’s
coefficient for each pair of words <script type="math/tex">e_i, f_j</script> is:</p>

<p>$$ \delta(i,j) = \frac{2 \times C(e_i, f_j)}{C(e_i) +C(f_j)} $$</p>

<p>The default aligner will align any word pair <script type="math/tex">e_i, f_j</script> with a
coefficient <script type="math/tex">\delta(i,j)</script> over 0.5.  You can experiment with
different thresholds using <code class="highlighter-rouge">-t</code>.</p>

<h2 id="the-challenge">The Challenge</h2>

<p>The goal of this homework is to train a word alignment model using
a given set of sentence pairs in two languages and then produce a
word alignment for the data sets given to you.</p>

<p>You are only provided sentence pairs without any alignments, hence
this is an example of <em>unsupervised learning</em>.  The plan is to learn
a conditional probability model <script type="math/tex">\Pr(\textbf{f} \mid \textbf{e})</script>
of a French sentence <script type="math/tex">\textbf{f}</script> given an English sentence
<script type="math/tex">\textbf{e}</script>.  You are given a dataset <script type="math/tex">{\cal D}</script> of <script type="math/tex">1, \ldots,
N</script> sentence pairs that are known to be translation pairs:</p>

<p>$${\cal D} = \{ (\textbf{f}^{(1)}, \textbf{e}^{(1)}), \ldots,
(\textbf{f}^{(N)}, \textbf{e}^{(N)}) \}$$</p>

<p>There are two data sets provided to you. You will develop your
aligner using French-English sentence pairs:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>data/hansards.fr
data/hansards.en
</code></pre>
</div>

<p>Use the default Dice alignment to align the first 10,000 lines of
the training data.</p>

<div class="highlighter-rouge"><pre class="highlight"><code>python default.py -n 10000 &gt; dice.a
</code></pre>
</div>

<p>You can check the validity of your alignment file:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>python check-alignments.py -i dice.a
</code></pre>
</div>

<p>This will print out all the valid alignments in your input file.
Ignore the following warning:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>WARNING:root:WARNING (check-alignments.py): bitext is longer than alignment
</code></pre>
</div>

<p>Evaluate the output alignments against the reference French-English
alignments:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>python score-alignments.py -i dice.a
</code></pre>
</div>

<p>You will see an ASCII-based graphical view of each alignment compared
to the true alignment (guessed alignment versus sure and possible
alignments from truth). At the end you will see the precision,
recall and the alignment error rate (AER) scores of your alignments.
For precision and recall, the higher the better. For AER the lower
the better.</p>

<div class="highlighter-rouge"><pre class="highlight"><code> Alignment 8  KEY: ( ) = guessed, * = sure, ? = possible
  ---------------------------------------
 |(*)( )                                  | monsieur
 |    ? ( )            ( )( )   ( )   ( ) | le
 |    *                                   | Orateur
 |      (*)            ( )( )   ( )   ( ) | ,
 |          *                             | ma
 |            (*)                         | question
 |                ?  ?                    | se
 |                ?  ?                    | adresse
 |                     (*)( )   ( )   ( ) | à
 |      ( )            ( )(*)   ( )   ( ) | le
 |                           (*)          | ministre
 |                                        | chargé
 |      ( )            ( )( )   (*)   ( ) | de
 |      ( )            ( )( )   (?) ? ( ) | les
 |                                  *     | transports
 |      ( )            ( )( )   ( )   (*) | .
  ---------------------------------------
   M  S  ,  m  q  i  d  t  t  M  o  T  . 
   r  p     y  u  s  i  o  h  i  f  r    
   .  e        e     r     e  n     a    
      a        s     e        i     n    
      k        t     c        s     s    
      e        i     t        t     p    
      r        o     e        e     o    
               n     d        r     r    
                                    t    
</code></pre>
</div>

<p>You can also do it all at once:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>python default.py -n 10000 | python check-alignments.py | python score-alignments.py
</code></pre>
</div>

<h3 id="alignment-error-rate">Alignment Error Rate</h3>

<p>AER is used to evaluate the output. The alignments created by humans
for the evaluation are divided into two types:</p>

<ul>
  <li>Sure alignments <script type="math/tex">S</script> which use <code class="highlighter-rouge">-</code> as the separator, e.g. <code class="highlighter-rouge">0-0</code></li>
  <li>Unsure alignments use <code class="highlighter-rouge">?</code> as the separator, e.g. <code class="highlighter-rouge">0?0</code></li>
  <li>Possible alignments <script type="math/tex">P</script> is the union of Sure and Unsure alignments: <script type="math/tex">S \subseteq P</script></li>
</ul>

<p>The quality of an alignment <script type="math/tex">A = \{ (j, a_j) \mid e_{a_j} != \textrm{NULL} \}</script> is
computed using precision and recall:</p>

<p>$$ \textrm{precision} = \frac{ | A \cap P | }{ |A| } $$</p>

<p>$$ \textrm{recall} = \frac{ | A \cap S | }{ |S| } $$</p>

<p>Alignment error rate (AER) combines precision and recall:</p>

<p>$$ \textrm{AER} = 1 - \left( \frac{ |A \cap S| + |A \cap P|  }{ |A| + |S| } \right) $$</p>

<h3 id="the-leaderboard">The Leaderboard</h3>

<p><strong>Important: You need upload the alignments on German-English data
to the leaderboard</strong></p>

<p>In this homework, you will be developing your aligner on French-English
data, but you will be uploading your alignment file for the provided
German-English data. The German-English sentence pairs are in the
files:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>data/europarl.de
data/europarl.en
</code></pre>
</div>

<p>To upload the alignment using <code class="highlighter-rouge">default.py</code>:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>python default.py -p europarl -f de -n 10000 &gt; output.a
head -1000 output.a &gt; upload.a
</code></pre>
</div>

<p>There is a size limit to your uploads to the leaderboard. Make sure
you upload only the first 1000 lines of the alignment file to the 
leaderboard.</p>

<p>When you develop your own aligner called <code class="highlighter-rouge">your-aligner.py</code> you have
to make sure you use the same command line arguments as <code class="highlighter-rouge">default.py</code>:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>python your-aligner.py -p europarl -f de -n 10000 &gt; output.a
head -1000 output.a &gt; upload.a
</code></pre>
</div>

<p>Then upload the file <code class="highlighter-rouge">upload.a</code> to the leaderboard for Homework 3
on <a href="https://sfu-nlp-class.appspot.com">sfu-nlp-class.appspot.com</a></p>

<h3 id="the-baseline">The Baseline</h3>

<h4 id="the-word-alignment-model">The word alignment model</h4>

<p>The baseline model is a simple model that uses a <em>word-to-word</em> or
<em>lexical</em> translation model. It has only one set of parameters: a
conditional probability <script type="math/tex">t(f \mid e)</script> where <script type="math/tex">f</script> is a French
word and <script type="math/tex">e</script> is an English word. We will build the model
<script type="math/tex">\Pr(\textbf{f} \mid \textbf{e})</script> using <script type="math/tex">t(\cdot \mid \cdot)</script>.</p>

<p>Pick one translation pair from the data <script type="math/tex">{\cal D}</script>. Let the French
sentence be <script type="math/tex">\mathbf{f} = (f_1, \ldots, f_I)</script> and the English
sentence <script type="math/tex">\mathbf{e} = (e_1, \ldots, e_J)</script>.  Now we make a big
assumption: that each French word can only map to exactly one English
word. This means that we can represent an alignment <script type="math/tex">\textbf{a}</script>
of the French words by: <script type="math/tex">\textbf{a} = (a_1, \ldots, a_I)</script>. There
is one <script type="math/tex">a_i</script> for each French word <script type="math/tex">f_i</script> which corresponds to
an English word <script type="math/tex">e_{a_i}</script>. If <script type="math/tex">a_i</script> is allowed to be <script type="math/tex">0</script> then
it means that a French word <script type="math/tex">f_i</script> is not mapped to any English
word. Setting <script type="math/tex">a_i</script> to <script type="math/tex">0</script> is called aligning <script type="math/tex">f_i</script> to <em>null</em>.</p>

<p>$$ \Pr(\mathbf{f}, \textbf{a} \mid \mathbf{e}) = \prod_{i=1}^I
t(f_i \mid e_{a_i})$$</p>

<p>Assume we have a three word French sentence (<script type="math/tex">I = 3</script>) sentence-aligned
to a three word English sentence (<script type="math/tex">J = 3</script>).  If the alignment
<script type="math/tex">\textbf{a} = (1,3,2)</script>, that is, <script type="math/tex">a_1 = 1</script>, <script type="math/tex">a_2 = 3</script>, and
<script type="math/tex">a_3 = 2</script> we can derive the probability of this sentence pair
alignment to be:</p>

<p>$$\Pr(\mathbf{f}, \textbf{a} \mid \mathbf{e}) = t(f_1 \mid e_1)
\cdot t(f_2 \mid e_3) \cdot t(f_3 \mid e_2)$$</p>

<p>In this simple model, we allow any alignment function that maps any
word in the source sentence to any word in the target sentence (no
matter how far apart they are). The alignments are not provided to
us, so we remove the alignments by summing over them<sup id="fnref:2"><a href="#fn:2" class="footnote">1</a></sup>:</p>

<p>$$
\begin{eqnarray*}
\Pr(\mathbf{f} \mid \mathbf{e}, t) &amp; = &amp; \sum_{\textbf{a}} \Pr(\mathbf{f}, \textbf{a} \mid \mathbf{e}, t) \\
&amp; = &amp; \sum_{a_1=1}^J \cdots \sum_{a_I=1}^J  \prod_{i=1}^I t(f_i \mid e_{a_i}) \\
&amp;&amp; \textrm{(this computes all possible alignments)} \\
&amp; = &amp; \prod_{i=1}^I \sum_{j=1}^J t(f_i \mid e_j) \\
&amp;&amp; \textrm{(after conversion of $J^I$ terms into $I \cdot J$ terms)}
\end{eqnarray*}
$$</p>

<p>We wish to learn the parameters <script type="math/tex">t(\cdot \mid \cdot)</script> that maximize
the log-likelihood of the training data:</p>

<p>$$ \arg\max_{t} L(t) = \arg\max_{t} \sum_s \log \Pr(\mathbf{f}^{(s)} \mid
\mathbf{e}^{(s)}, t) $$</p>

<h4 id="training-the-model">Training the model</h4>

<p>In order to estimate the parameters <script type="math/tex">t(\cdot \mid \cdot)</script>
we start with an initial estimate <script type="math/tex">t_0</script> and modify it iteratively
to get <script type="math/tex">t_1, t_2, \ldots</script>. The parameter updates are derived
for each French word <script type="math/tex">f_i</script> and English word <script type="math/tex">e_j</script> as follows:</p>

<p>$$t_k(f_i \mid e_j) = \sum_{s=1}^N \sum_{(f_i, e_j) \in (\textbf{f}^{(s)}, \textbf{e}^{(s)})} \frac{ \textrm{count}(f_i, e_j, \textbf{f}^{(s)}, \textbf{e}^{(s)}) }{ \textrm{count}(e_j, \textbf{f}^{(s)}, \textbf{e}^{(s)}) }$$</p>

<p>These counts are <em>expected counts</em> over all possible alignments,
and each alignment has a probability computed using <script type="math/tex">t_{k-1}</script>.
Using maximum likelihood, each alignment between <script type="math/tex">f_i</script> and <script type="math/tex">e_j</script>
is the number of times we observe an alignment between <script type="math/tex">f_i</script> and
<script type="math/tex">e_j</script> times the probability of that alignment divided by the total
of all other alignments to other French words observed for <script type="math/tex">e_j</script>
times the probability of each of those alignments.</p>

<p>$$
\begin{eqnarray*}
\textrm{count}(f_i, e_j, \textbf{f}, \textbf{e}) &amp; = &amp; \frac{ t_{k-1}(f_i \mid e_j) }{ \Pr(\textbf{f} \mid \textbf{e}, t_{k-1}) } \\
&amp; = &amp; \frac{ t_{k-1}(f_i \mid e_j) }{ \sum_{a_i=1}^J t_{k-1}(f_i \mid e_{a_i}) } \\
\textrm{count}(e_j, \textbf{f}, \textbf{e}) &amp; = &amp; \sum_{i=1}^I \textrm{count}(f_i, e_j, \textbf{f}, \textbf{e})
\end{eqnarray*}
$$</p>

<p>The description of the training algorithm is very compressed here.
You will have to work through the background reading below in order
to fully understand the steps. Pseudo-code for the training algorithm
is given below.</p>

<h5 id="algorithm-training-a-lexical-word-alignment-model">Algorithm: Training a lexical word alignment model</h5>

<hr />

<ul class="list-unstyled">
  <li><script type="math/tex">k</script> = 0</li>
  <li>Initialize <script type="math/tex">t_0</script> <strong>## Easy choice: initialize uniformly ##</strong></li>
  <li>repeat
    <ul>
      <li><script type="math/tex">k</script> += 1</li>
      <li>Initialize all counts to zero</li>
      <li>for each <script type="math/tex">(\textbf{f}, \textbf{e})</script> in <script type="math/tex">{\cal D}</script>
        <ul>
          <li>for each <script type="math/tex">f_i</script> in <script type="math/tex">\textbf{f}</script>
            <ul>
              <li><script type="math/tex">Z</script> = 0 <strong>## Z commonly denotes a normalization term ##</strong></li>
              <li>for each <script type="math/tex">e_j</script> in <script type="math/tex">\textbf{e}</script>
                <ul>
                  <li><script type="math/tex">Z</script> += <script type="math/tex">t_{k-1}(f_i \mid e_j)</script></li>
                </ul>
              </li>
              <li>for each <script type="math/tex">e_j</script> in <script type="math/tex">\textbf{e}</script>
                <ul>
                  <li><code class="highlighter-rouge">c</code> = <script type="math/tex">t_{k-1}(f_i \mid e_j) / Z</script></li>
                  <li>count(<script type="math/tex">f_i</script>, <script type="math/tex">e_j</script>) += <code class="highlighter-rouge">c</code></li>
                  <li>count(<script type="math/tex">e_j</script>) += <code class="highlighter-rouge">c</code></li>
                </ul>
              </li>
            </ul>
          </li>
        </ul>
      </li>
      <li>for each (<script type="math/tex">f</script>, <script type="math/tex">e</script>) in count
        <ul>
          <li>Set new parameters: <script type="math/tex">t_k(f \mid e)</script> =  count(<script type="math/tex">f,e</script>) / count(<script type="math/tex">e</script>)</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>until convergence <strong>## See below for convergence tests ##</strong></li>
</ul>
<hr />

<h4 id="initialization">Initialization</h4>

<p>Initializing uniformly means that every French word is equally
likely for every English word: for all <script type="math/tex">{e,f}</script> we initialize
<script type="math/tex">t_0(f \mid e) = \frac{1}{V_f}</script> where <script type="math/tex">V_f</script> is the French
vocabulary size. This ensures that <script type="math/tex">\sum_f t(f \mid e) = 1</script>.</p>

<h4 id="convergence">Convergence</h4>

<p>The theory behind this algorithm states that the iterative updates
have the following property:</p>

<p>$$L(t_k) \geq L(t_{k-1})$$</p>

<p>We can check for convergence by checking if the value of <script type="math/tex">L(t)</script>
does not change much from the previous iteration (difference from
previous iteration is less than <script type="math/tex">10^{-4}</script>, for example).</p>

<p>The objective for the baseline method, <script type="math/tex">L(t)</script>, can be shown to
be an example of convex optimization, which means we are guaranteed
to find the value of <script type="math/tex">t</script> that maximizes <script type="math/tex">L(t)</script> <em>in the limit</em>.
However, this could mean hundreds or thousands of iterations for
any given data set.</p>

<p>Most practitioners simply iterate over the training data for 3 to
5 iterations.</p>

<h4 id="decoding-compute-the-argmax-word-alignment">Decoding: compute the <script type="math/tex">\arg\max</script> word alignment</h4>

<p>We have trained an alignment model so far, but what we really need
is the <script type="math/tex">\arg\max</script> alignment for a given translation pair.</p>

<p>$$ 
\hat{\textbf{a}} = \arg\max_{\textbf{a}} \Pr(\textbf{a} \mid \textbf{e}, \textbf{f})
$$</p>

<p>The best alignment to a target sentence in our simple baseline model
is obtained by simply finding the best alignment for each word in
the source sentence independently of the other words. For each
French word <script type="math/tex">f_i</script> in the source sentence the best alignment is
given by:</p>

<p>$$ 
\hat{a_i} = \arg\max_{a_i} t(f_i \mid e_{a_i}) 
$$</p>

<p>Pseudo-code for this <script type="math/tex">\arg\max</script> search is given below.</p>

<h5 id="algorithm-decoding-the-best-alignment">Algorithm: Decoding the best alignment</h5>

<hr />

<ul class="list-unstyled">
  <li>for each <script type="math/tex">(\textbf{f}, \textbf{e})</script> in <script type="math/tex">{\cal D}</script>
    <ul>
      <li>for each <script type="math/tex">f_i</script> in <script type="math/tex">\textbf{f}</script>
        <ul>
          <li><code class="highlighter-rouge">bestp</code> = 0</li>
          <li><code class="highlighter-rouge">bestj</code> = 0</li>
          <li>for each <script type="math/tex">e_j</script> in <script type="math/tex">\textbf{e}</script>
            <ul>
              <li>if <script type="math/tex">t(f_i \mid e_j)</script> &gt; <code class="highlighter-rouge">bestp</code>
                <ul>
                  <li><code class="highlighter-rouge">bestp</code> = <script type="math/tex">t(f_i \mid e_j)</script></li>
                  <li><code class="highlighter-rouge">bestj</code> = <script type="math/tex">j</script></li>
                </ul>
              </li>
            </ul>
          </li>
          <li>align <script type="math/tex">f_i</script> to <script type="math/tex">e_{\texttt{bestj}}</script></li>
        </ul>
      </li>
    </ul>
  </li>
</ul>
<hr />

<h4 id="background-reading">Background reading</h4>

<p>The model and training and decoding algorithms and the theory behind
the algorithms is covered in the following basic tutorial (which
is easier to understand than the original research papers):</p>

<blockquote>
  <p>Adam Lopez. <a href="http://www.cs.jhu.edu/~alopez/papers/model1-note.pdf">Word Alignment and the Expectation-Maximization
Algorithm</a>.</p>
</blockquote>

<p>Easier to understand, but considerably longer is the following
workbook:</p>

<blockquote>
  <p>Kevin Knight. <a href="http://www.isi.edu/natural-language/mt/wkbk.pdf">A Statistical MT Tutorial
Workbook</a>. 1999.</p>
</blockquote>

<hr />

<h3 id="your-task">Your Task</h3>

<p>Developing an aligner using the simple alignment algorithms (described
in the above pseudo-code) is good enough to get an alignment error
rate (AER) that is close to the performance of the baseline system
on the leaderboard.  But getting closer to the best known accuracy
on this task<sup id="fnref:1"><a href="#fn:1" class="footnote">2</a></sup> is a more interesting challenge. To get full credit
you <strong>must</strong> experiment with at least one extension of the baseline
and document your work. Here are some ideas:</p>

<ul>
  <li>There are better ways to find the best alignment:
    <ul>
      <li>Align using <script type="math/tex">\Pr(\textbf{f} \mid \textbf{e})</script> and also align using <script type="math/tex">\Pr(\textbf{e} \mid \textbf{f})</script>, then decode the best alignment using each model independently and then report the alignments that are the intersection of these two alignment sets.</li>
      <li><a href="http://aclweb.org/anthology/N/N06/N06-1014.pdf">Use the posterior probability to decode</a>: <script type="math/tex">\hat{a_i} = \arg\max_{a_i} \Pr(a_i \mid \textbf{f}, \textbf{e})</script></li>
    </ul>
  </li>
  <li><a href="http://aclweb.org/anthology/P/P04/P04-1066.pdf">Add <em>null</em> words to the source sentence</a>.</li>
  <li>There are <a href="http://aclweb.org/anthology/P/P04/P04-1066.pdf">better ways to initialize the parameters</a> that lead to better alignments especially if you run only for 5 iterations.</li>
  <li>Implement a <a href="http://aclweb.org/anthology/C/C96/C96-2141.pdf">HMM-based alignment model</a>.</li>
  <li>Add part of speech tags to one language or both and use them, for example, to separate <script type="math/tex">t( \textrm{usine} \mid \textrm{plant, N})</script> and <script type="math/tex">t( \textrm{plante} \mid \textrm{plant, N})</script> from the alignment <script type="math/tex">t( \textrm{planter} \mid \textrm{plant, V} )</script>.</li>
  <li>Add phrasal chunks to one language or both and reward alignments within phrasal chunks and/or penalize alignments across phrasal chunks.</li>
  <li>Implement the more sophisticated alignment models from the <a href="http://www.isi.edu/natural-language/mt/wkbk.pdf">Statistical MT Tutorial Workbook</a>.</li>
</ul>

<p>But the sky’s the limit! You are welcome to design your own model,
as long as you follow the ground rules:</p>

<h2 id="ground-rules">Ground Rules</h2>

<ul>
  <li>Each group should submit using one person as the designated uploader.</li>
  <li>You must turn in three things:
    <ol>
      <li>The alignment of the first 1000 lines of the German-English data set uploaded to the <a href="http://sfu-nlp-class.appspot.com">leaderboard submission site</a> using the instructions given above. You can upload new output as often as you like, up until the assignment deadline. The Submit button for showing the test set scores will be unavailable until after the homework deadline and grace days have passed.  The German-English alignments will be evaluated for the leaderboard, but the <code class="highlighter-rouge">score-alignments.py</code> program on the French-English alignments will give you a good idea of how well you’re doing.</li>
      <li>Your code. Each group should assign one member to upload the source code to <a href="https://courses.cs.sfu.ca">Coursys</a> as the submission for Homework 3. The code should be self-contained, self-documenting, and easy to use. It should use the same input and output assumptions of <code class="highlighter-rouge">default.py</code>.</li>
      <li>A clear, mathematical description of your algorithm and its motivation written in scientific style. This needn’t be long, but it should be clear enough that one of your fellow students could re-implement it exactly. Include the file for this writeup as part of the tarball or zip file you will upload to <a href="https://courses.cs.sfu.ca">Coursys</a>. Include also how your group divided up the work load and each group member’s contribution to the homework solution.</li>
    </ol>
  </li>
  <li>You cannot use data or code resources outside of what is provided to you. You can use NLTK but not the NLTK aligner implementation. You cannot use any public implemenation of word alignment such as <code class="highlighter-rouge">GIZA++</code>, <code class="highlighter-rouge">fast_align</code>, or any other open source aligner.</li>
  <li>For the written description of your algorithm, you can use plain ASCII but for math equations it is better to use either <a href="http://www.latex-project.org/">latex</a> or <a href="https://github.com/gettalong/kramdown">kramdown</a>.  Do <strong>not</strong> use any proprietary or binary file formats such as Microsoft Word.</li>
</ul>

<p>If you have any questions or you’re confused about anything, just ask.</p>

<h4 id="acknowledgements">Acknowledgements</h4>

<p>This assignment is adapted from the word alignment homework developed
by <a href="http://cs.jhu.edu/~post/">Matt Post</a> and <a href="http://cs.jhu.edu/~alopez/">Adam
Lopez</a> based on an original homework
developed by <a href="http://homepages.inf.ed.ac.uk/pkoehn/">Philipp Koehn</a>
and later modified by <a href="http://www.denero.org/">John DeNero</a>. It
incorporates some ideas from <a href="http://www.cs.cmu.edu/~cdyer">Chris Dyer</a>.</p>

<!--
    le droit de permis passe donc de $ 25 à $ 500 .
    we see the licence fee going up from $ 25 to $ 500 .
-->

<!--
% 0 le 1 droit 2 de 3 permis 4 passe 5 donc 6 de 7 \$ 8 25 9 \`a 10 \$ 11 500 12 . \\
% 0 we 1 see 2 the 3 licence 4 fee 5 going 6 up 7 from 8 \$ 9 25 10 to 11 \$ 12 500 13 .
    0-2 1-4 3-3 4-5 4-6 5-7 7-8 8-9 9-10 10-11 11-12 12-13
-->

<!--
| 0 `le` | 2 `the` |
| 1 `droit` | 4 `fee` |
| 2 `de` | |
| 3 `permis` | 3 `license` |
| 4 `passe` | 5 `going` |
| 4 `passe` | 6 `up` |
| 5 `donc` | 7 `from` |
| 6 `de` | |
| 7 `$` | 8 `$` |
| 8 `25` | 9 `25` |
| 9 `à` | 10 `to` |
| 10 `$` | 11 `$` |
| 11 `500` | 12 `500` |
| 12 `.` | 13 `.` |
{: .table}
-->

<div class="footnotes">
  <ol>
    <li id="fn:2">
      <p>For each assignment of <script type="math/tex">a_i</script> which is a sum over <script type="math/tex">J</script> terms we have to do <script type="math/tex">I</script> multiplications, so the total number of terms is <script type="math/tex">J^I</script>. However, if you allow assignment of <script type="math/tex">a_i</script> to <script type="math/tex">0</script> (alignment to <em>null</em>) then the number of terms is <script type="math/tex">(J+1)^I</script>. <a href="#fnref:2" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:1">
      <p>The best known alignment error rate on this task using the data provided to you for French-English is around 19 and for German-English the best error rate is approximately 12.5 according to this <a href="http://aclweb.org/anthology/P/P04/P04-1023.pdf">comparison of different alignment models</a>. <a href="#fnref:1" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div>

        </div>
      </div>

      <footer class="text-center text-muted">
        <hr/>
        Last updated September 06, 2016.<br/>
        Forked from the JHU MT class code on <a href="https://github.com/mt-class/jhu">github <i class="fa fa-github-alt"></i></a> by <a href="https://github.com/mjpost">Matt Post</a> and <a href="https://github.com/alopez">Adam Lopez</a>.<br/>
        <br/><br/>
      </footer>
    </div>

    <!-- Page content of course! -->
    <!-- JS and analytics only. -->
    <!-- Bootstrap core JavaScript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="./dist/js/bootstrap.js"></script>
    <script type="text/javascript">
      $(document).ready(function(){
        $("#homework").addClass("active");
      });
    </script>
  </body>
</html>
